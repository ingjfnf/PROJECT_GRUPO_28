{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e1df45e-966a-4dfa-bbfc-d83cc7656d24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d79a98f-954d-4847-9cd7-71b184194960",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 02:54:28 INFO mlflow.tracking.fluent: Experiment with name '/Users/jf.neiraf1@uniandes.edu.co/Student_Performance_FINAL' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/331492855821372', creation_time=1731207268786, experiment_id='331492855821372', last_update_time=1731207268786, lifecycle_stage='active', name='/Users/jf.neiraf1@uniandes.edu.co/Student_Performance_FINAL', tags={'mlflow.experiment.sourceName': '/Users/jf.neiraf1@uniandes.edu.co/Student_Performance_FINAL',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'jf.neiraf1@uniandes.edu.co',\n",
       " 'mlflow.ownerId': '3974471921678252'}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos el conjunto de datos\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Fibovin/des_modelos_1/refs/heads/main/Student_Performance.csv\")\n",
    "\n",
    "# Codificamos la variable categórica\n",
    "df['Extracurricular Activities'] = df['Extracurricular Activities'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Dividimos el conjunto de datos en características y variable objetivo\n",
    "X = df.drop(columns=['Performance Index'])\n",
    "y = df['Performance Index']\n",
    "\n",
    "# Dividimos el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configuramos el experimento de MLflow\n",
    "mlflow.set_experiment(\"/Users/jf.neiraf1@uniandes.edu.co/Student_Performance_FINAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1c20130-8bf9-4a52-be8f-277d774450d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n2024/11/10 02:57:34 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.11.4/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de Prueba:\nR²: 0.9889832909573145\nMean Squared Error: 4.082628398521853\nMean Absolute Error: 1.6111213463123044\n"
     ]
    }
   ],
   "source": [
    "# Definimos y ejecutamos el experimento con MLflow para la regresión lineal\n",
    "with mlflow.start_run(run_name=\"MEJOR MODELO REGRESION LINEAL\"):\n",
    "    # Creamos y entrenamos el modelo de regresión lineal simple\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_train, y_train)\n",
    "\n",
    "    # Realizamos predicciones en el conjunto de prueba\n",
    "    y_test_pred = linear_model.predict(X_test)\n",
    "\n",
    "    # Calculamos y registramos las métricas para el conjunto de prueba\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    mlflow.log_metric(\"r2\", r2_test)\n",
    "    mlflow.log_metric(\"mse\", mse_test)\n",
    "    mlflow.log_metric(\"mae\", mae_test)\n",
    "\n",
    "    # Registramos el modelo de regresión lineal en MLflow\n",
    "    mlflow.sklearn.log_model(linear_model, \"linear-regression-model\")\n",
    "\n",
    "    # Imprimimos las métricas para verificar\n",
    "    print(\"Conjunto de Prueba:\")\n",
    "    print(f\"R²: {r2_test}\")\n",
    "    print(f\"Mean Squared Error: {mse_test}\")\n",
    "    print(f\"Mean Absolute Error: {mae_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20ccb57e-554e-4201-953d-f9fd54f33e66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 02:59:17 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.11.4/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de Prueba - SVR:\nR²: 0.9889779818430801\nMean Squared Error: 4.084595877236296\nMean Absolute Error: 1.6117598399098356\n"
     ]
    }
   ],
   "source": [
    "# Definimos y ejecutamos el experimento con MLflow para el modelo SVR\n",
    "with mlflow.start_run(run_name=\"MEJOR MODELO SVR\"):\n",
    "    # Creamos y entrenamos el modelo SVR con kernel lineal\n",
    "    svr_model = SVR(kernel=\"linear\")\n",
    "    svr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Realizamos predicciones en el conjunto de prueba\n",
    "    y_test_pred_svr = svr_model.predict(X_test)\n",
    "\n",
    "    # Calculamos y registramos las métricas para el conjunto de prueba\n",
    "    r2_test_svr = r2_score(y_test, y_test_pred_svr)\n",
    "    mse_test_svr = mean_squared_error(y_test, y_test_pred_svr)\n",
    "    mae_test_svr = mean_absolute_error(y_test, y_test_pred_svr)\n",
    "    \n",
    "    mlflow.log_metric(\"r2\", r2_test_svr)\n",
    "    mlflow.log_metric(\"mse\", mse_test_svr)\n",
    "    mlflow.log_metric(\"mae\", mae_test_svr)\n",
    "\n",
    "    # Registramos el modelo SVR en MLflow\n",
    "    mlflow.sklearn.log_model(svr_model, \"svr-linear-model\")\n",
    "\n",
    "    # Imprimimos las métricas para verificar\n",
    "    print(\"Conjunto de Prueba - SVR:\")\n",
    "    print(f\"R²: {r2_test_svr}\")\n",
    "    print(f\"Mean Squared Error: {mse_test_svr}\")\n",
    "    print(f\"Mean Absolute Error: {mae_test_svr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06382021-5e30-4c41-9d62-9d0ac16a4aae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/10 03:04:56 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.11.4/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de Prueba:\nR²: 0.9842770387732579\nMean Squared Error: 5.8266954100757244\nMean Absolute Error: 1.9034931306771197\n"
     ]
    }
   ],
   "source": [
    "# Definimos y ejecutamos el experimento con MLflow para el modelo optimizado\n",
    "with mlflow.start_run(run_name=\"MEJOR MODELO ARBOL DECISION\"):\n",
    "    # Creamos el modelo con los mejores hiperparámetros\n",
    "    optimized_tree_model = DecisionTreeRegressor(max_depth=10, min_samples_leaf=4, min_samples_split=10, random_state=42)\n",
    "    optimized_tree_model.fit(X_train, y_train)\n",
    "\n",
    "    # Realizamos predicciones en el conjunto de prueba\n",
    "    y_test_pred_optimized = optimized_tree_model.predict(X_test)\n",
    "\n",
    "    # Calculamos y registramos las métricas para el conjunto de prueba\n",
    "    r2_test_optimized = r2_score(y_test, y_test_pred_optimized)\n",
    "    mse_test_optimized = mean_squared_error(y_test, y_test_pred_optimized)\n",
    "    mae_test_optimized = mean_absolute_error(y_test, y_test_pred_optimized)\n",
    "    \n",
    "    mlflow.log_metric(\"r2\", r2_test_optimized)\n",
    "    mlflow.log_metric(\"mse\", mse_test_optimized)\n",
    "    mlflow.log_metric(\"mae\", mae_test_optimized)\n",
    "\n",
    "    # Registramos el modelo optimizado en MLflow\n",
    "    mlflow.sklearn.log_model(optimized_tree_model, \"decision-tree-model\")\n",
    "\n",
    "    # Imprimimos las métricas para verificar\n",
    "    print(\"Conjunto de Prueba:\")\n",
    "    print(f\"R²: {r2_test_optimized}\")\n",
    "    print(f\"Mean Squared Error: {mse_test_optimized}\")\n",
    "    print(f\"Mean Absolute Error: {mae_test_optimized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "697caab2-4549-4337-a904-eae4f390a51d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "REGRESION MODELO FINAL",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
